{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7793c6a-0058-4894-876b-dc6916ba89f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1493420296.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    git clone https://github.com/xKimChip/IMDB-NLP.git\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "git clone https://github.com/xKimChip/IMDB-NLP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5352a08-a359-4b67-abc9-6149b1d387ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "seed = 1212\n",
    "seed2 = 2121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324bab4f-6d4a-48f5-a7d3-c5341ae38db6",
   "metadata": {},
   "source": [
    "#### Read in the data set using pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "031b6179-61af-4eb0-8746-08daeb387d11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 28\u001b[0m\n\u001b[0;32m     22\u001b[0m training_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m: negative_train_reviews \u001b[38;5;241m+\u001b[39m positive_train_reviews,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(negative_train_reviews) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(positive_train_reviews)\n\u001b[0;32m     25\u001b[0m })\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#training_data['review'] = training_data['review'].str.strip() #Uncomment to clean\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#Shuffle\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m training_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m testing_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m: negative_test_reviews \u001b[38;5;241m+\u001b[39m positive_test_reviews,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(negative_test_reviews) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(positive_test_reviews)\n\u001b[0;32m     33\u001b[0m })\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#testing_data['review'] = testing_data['review'].str.strip()\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#Shuffle\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def load_reviews(folder_path):\n",
    "    reviews = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):  # Process only .txt files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                reviews.extend(file.readlines())  # Add lines from the file\n",
    "    return reviews\n",
    "\n",
    "neg_train_paths = 'aclImdb/train/neg'\n",
    "pos_train_paths = 'aclImdb/train/pos'\n",
    "\n",
    "neg_test_paths = 'aclImdb/test/neg'\n",
    "pos_test_paths = 'aclImdb/test/pos'\n",
    "\n",
    "negative_train_reviews = load_reviews(neg_train_paths)\n",
    "positive_train_reviews = load_reviews(pos_train_paths)\n",
    "\n",
    "negative_test_reviews = load_reviews(neg_test_paths)\n",
    "positive_test_reviews = load_reviews(pos_test_paths)\n",
    "\n",
    "training_data = pd.DataFrame({\n",
    "    'review': negative_train_reviews + positive_train_reviews,\n",
    "    'label': [0] * len(negative_train_reviews) + [1] * len(positive_train_reviews)\n",
    "})\n",
    "#training_data['review'] = training_data['review'].str.strip() #Uncomment to clean\n",
    "#Shuffle\n",
    "training_data = training_data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "testing_data = pd.DataFrame({\n",
    "    'review': negative_test_reviews + positive_test_reviews,\n",
    "    'label': [0] * len(negative_test_reviews) + [1] * len(positive_test_reviews)\n",
    "})\n",
    "#testing_data['review'] = testing_data['review'].str.strip()\n",
    "#Shuffle\n",
    "testing_data = testing_data.sample(frac=1, random_state=seed2).reset_index(drop=True)\n",
    "\n",
    "#Batch if wanted\n",
    "#training_data = training_data[:5000]\n",
    "#testing_data = testing_data[:5000]\n",
    "\n",
    "X_train = training_data['review']\n",
    "y_train = training_data['label']\n",
    "\n",
    "X_test = testing_data['review']\n",
    "y_test = testing_data['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05401c05-91b1-4ab1-8fee-11599ac9d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/aclImdb'\n",
    "train_data_path = os.path.join(data_dir, 'train.csv')\n",
    "test_data_path = os.path.join(data_dir, 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
